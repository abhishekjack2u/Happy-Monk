{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77038b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tflearn) (1.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tflearn) (1.15.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tflearn) (8.2.0)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Building wheel for tflearn (setup.py): started\n",
      "  Building wheel for tflearn (setup.py): finished with status 'done'\n",
      "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127300 sha256=ee829118df89f96fb182cb77edaac34ea1e06eaa8b311e6517871ab413a76abc\n",
      "  Stored in directory: c:\\users\\abhis\\appdata\\local\\pip\\cache\\wheels\\65\\9b\\15\\cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99f1d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2\n",
      "  Downloading tensorflow-2.2.0-cp38-cp38-win_amd64.whl (459.2 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (3.17.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.12.1)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.38.1-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (0.36.2)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp38-cp38-win_amd64.whl (31.0 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.20.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (52.0.0.post20210125)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=255374e29dea56243b0010619720d2250c8bfdf930c421639c57b109d248f9e6\n",
      "  Stored in directory: c:\\users\\abhis\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, google-pasta, gast, astunparse, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 gast-0.3.3 google-auth-1.32.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.38.1 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 scipy-1.4.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.8.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa50b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8026b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7bd1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0% 60276736 / 60270631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully downloaded 17flowers.tgz 60270631 bytes.\n",
      "File Extracted\n",
      "Starting to parse images...\n",
      "Parsing Done!\n"
     ]
    }
   ],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "x,y=oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3db805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89eb191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                69649     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 24,048,401\n",
      "Trainable params: 24,029,265\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=96,input_shape=(224,224,3),kernel_size=(11,11),strides=(4,4),padding=\"Valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(11,11),strides=(1,1),padding=\"Valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"Valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"Valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"Valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,input_shape=(224*224*3,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(17))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149b4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d17309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1088 samples, validate on 272 samples\n",
      "Epoch 1/5\n",
      "1088/1088 [==============================] - 67s 62ms/sample - loss: 3.9587 - acc: 0.2463 - val_loss: 52.1770 - val_acc: 0.0551\n",
      "Epoch 2/5\n",
      "1088/1088 [==============================] - 64s 59ms/sample - loss: 2.5895 - acc: 0.3502 - val_loss: 26.4796 - val_acc: 0.0993\n",
      "Epoch 3/5\n",
      "1088/1088 [==============================] - 65s 60ms/sample - loss: 1.9392 - acc: 0.4283 - val_loss: 7.3061 - val_acc: 0.1397\n",
      "Epoch 4/5\n",
      "1088/1088 [==============================] - 64s 59ms/sample - loss: 1.8786 - acc: 0.4789 - val_loss: 4.9803 - val_acc: 0.1728\n",
      "Epoch 5/5\n",
      "1088/1088 [==============================] - 65s 60ms/sample - loss: 1.6074 - acc: 0.5340 - val_loss: 2.6649 - val_acc: 0.3051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2603abe0f10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=64,epochs=5,verbose=1,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f85d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
